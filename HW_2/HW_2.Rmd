---
title: "Lab 2"
author: "Zara Waheed"
date: "4th Feb 2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width=6,fig.height=4 ,out.width="1\\linewidth")
pacman::p_load("class","ISLR","glmnet","ggplot2","arm","knitr","data.table","MASS","klaR","vcd","h2o","e1071", "class")
names(Auto)
```

### Question 6

## a) 
exp(-6 + 0.05*40 +1*3.5) / (1 + exp(-6 + 0.05*40 +1*3.5) )

## b) 
log(0.5/0.5) = -6 + hours * 0.05 + 3.5 
so,
log(0.5/0.5) 
(6 - 3.5 )/0.05 # 50 hours

### Question 8

We will use the method that has the smaller out-of-sample error rate.

### Question 9

## a) 

x/(1-x) = 0.37
x = 0.37*(1-x)
x = 0.37 - 0.37x
1.37x = 0.37
x = 0.37/1.37

## b)

0.16/(1-0.16) = 0.19
0.19 are the odds

### Question 13

```{r}
weekly <- ISLR2::Weekly
```

## a)

```{r}
cor(weekly[, -which(names(weekly) == "Direction")])
```

There doesn't seem to be significant correlation in the data.

## b)

```{r}
fit13b <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = weekly, family = "binomial")

summary(fit13b)
```

Lag2 appears to be statistically insignificant with respect to the p-value.

## c) 

```{r}
prob13c <- predict(fit13b, type = "response")
pred13c <- rep(times = dim(weekly)[1], x = "Down")
pred13c[prob13c > 0.5] <- "Up"
table(pred13c, weekly[["Direction"]])

mean(pred13c == weekly[["Direction"]])
```

We can be about 56% sure about the error.
The confusion matrix compares the LDA predictions to the true default statuses for the training observations in the Default data set.

## d)

```{r}
train <- weekly[["Year"]] <= 2008
test <- weekly[!train, ]
direction <- weekly[["Direction"]][!train]
fit13d <- glm(Direction ~ Lag2,
              data = weekly,
              family = "binomial",
              subset = train)
prob13d <- predict(fit13d, 
                    type = "response",
                    newdata = test)

# write a function to look at confusion matrix and accuracy
summ <- function(prob, test_true) {
  pred <- rep(times = length(prob), x = "Down")
  pred[prob > 0.5] <- "Up"
  
  return( list( cm = table(pred, test_true), 
               acc = mean(pred == test_true))
  )
}
summ(prob13d, direction)
```

## e)

```{r}
fit13e <- lda(Direction ~ Lag2,
               data = weekly,
               subset = train)
prob13e <- predict(fit13e, 
                    type = "response",
                    newdata = test)
summ(prob13e[["posterior"]][,"Up"], direction)
```

## f)

```{r}
fit13f <- qda(Direction ~ Lag2,
               data = weekly,
               subset = train)
prob13f <- predict(fit13f, type = "response", newdata = test)
summ(prob13f[["posterior"]][,"Up"], direction)
```

## g)

```{r}
set.seed(100)
pred13g <- knn( train = as.matrix(weekly[train, "Lag2"]),
                test =  as.matrix(weekly[!train, "Lag2"]),
                cl = weekly[train, "Direction"],
                k = 1 )
(list( cm = table(pred13g, direction), 
       acc = mean(pred13g == direction)) )
```

## h) Repeat (d) using naive Bayes.

```{r}
fit13h <- naiveBayes(Direction ~ Lag2,
               data = weekly,
               subset = train)
prob13h <- predict(fit13h,
                    type = "raw",
                    newdata = test)
summ(prob13h[,"Up"], direction)
```

## i) 

LDA seems to provide the best results


### Question 14

## a) 

```{r}
mpg01 = rep(0, nrow(Auto))
mpg01[Auto$mpg >= median(Auto$mpg)] = 1

new.auto = data.frame(Auto, mpg01)
```

## b)

```{r}
displacement <- boxplot(displacement~mpg01,data=new.auto, xlab="MPG > Median", ylab="Displacement")

acceleration <- boxplot(acceleration~mpg01,data=new.auto, xlab="MPG > Median", ylab="Acceleration")

horsepower <- boxplot(horsepower~mpg01,data=new.auto, xlab="MPG > Median", ylab="Horsepower")

weight <- boxplot(weight~mpg01,data=new.auto, xlab="MPG > Median", ylab="Weight")

displacement
acceleration
horsepower
weight
```

There seems to be some association with all the variables diplayed above. 

## c)

```{r}
set.seed(100)
sample = floor(0.8*nrow(new.auto))
train.s = sample(seq_len(nrow(new.auto)), size=sample)

train = new.auto[train.s,]
test = new.auto[-train.s, ]

y.train = train$mpg01
y.test = test$mpg01
```

## d)

```{r}
fit14d = lda(mpg01 ~ displacement + horsepower + weight, data=new.auto, subset = train.s)

pred14d = predict(fit14d, test)

# Confusion Matrix
class14d = pred14d$class
table(class14d, y.test) 

# error rate
mean(class14d != y.test)
```


## e)

```{r}
fit14e = qda(mpg01 ~ displacement + horsepower + weight, data=new.auto, subset = train.s)

pred14e = predict(fit14e, test)

# Confusion Matrix
class14e = pred14e$class
table(class14e, y.test)

# Error rate
mean(class14e != y.test)
```

## f)

```{r}
fit14f = glm(mpg01 ~ displacement + horsepower + weight, data=new.auto, subset = train.s, family=binomial)

pred14f = predict(fit14f, test, type="response")

## prediction vector
pred14f = rep(0, nrow(test))
pred14f[pred14f > .5] = 1
table(pred14f, y.test)

# Error rate
mean(pred14f != y.test)
```


## h)

```{r}
# prepare the data
train.x = scale(cbind(train$displacement + train$horsepower + train$weight))
train.y = train$mpg01

test.x = scale(cbind(test$displacement + test$horsepower + test$weight))
```

```{r}
## KNN for k=1

pred14h.1 = knn(train.x, test.x, train.y, k=1)

# error rate
mean(y.test != pred14h.1) 
```

```{r}
## KNN for k=2

pred14h.2 = knn(train.x, test.x, train.y, k=2)

# error rate
mean(y.test != pred14h.2) 
```

```{r}
## KNN for k=3

pred14h.3 = knn(train.x, test.x, train.y, k=3)

# error rate
mean(y.test != pred14h.3) 
```

```{r}
## KNN for k=5

pred14h.5 = knn(train.x, test.x, train.y, k=5)

# error rate
mean(y.test != pred14h.5) 
```

```{r}
## KNN for k=10

pred14h.10 = knn(train.x, test.x, train.y, k=10)

# error rate
mean(y.test != pred14h.10) 
```

### Question 15

## a)

```{r}
Power <- function(){
  x = 2^3 
  print(x)
}
```

## b)

```{r}
Power2 <- function(x,y){
  print(x^y)
}

Power2(3,8)
```

## c) 

```{r}
Power2(10,3)
Power2(8,17)
Power2(131,3)
```


## d) 

```{r}
Power3 <- function(x,y){
  return(x^y)
}
```

## e)

```{r}
x <- c(1:10)
y <- Power3(x,2)

plot(x,y,log="y")
```



## f)

```{r}
PlotPower <- function(x,a){
  y <- x^a
  plot(x,y)
}

PlotPower(x,3)
```



### Question 16


## Prepare and explore the data:
```{r}
library(MASS)
attach(Boston)

med.crime = median(crim)

crime = rep(0, length(crim)) 
crime[crim > med.crime] = 1
crime[1:20]
crime[1:20]

Boston.data = data.frame(Boston, crime)
```


```{r}
# create test and train datasets

train = 1:(dim(Boston)[1]/2)
test = (dim(Boston)[1]/2 + 1):dim(Boston)[1]

Boston.train = Boston.data[train,]
Boston.test = Boston.data[test,]
crime.test = crime[test]
```


## LDA

```{r}

set.seed(100)
lda.fit = lda(crime ~indus+nox+age+dis+rad+tax,
              data = Boston, subset = train)
lda.pred = predict(lda.fit, Boston.test)
lda.class = lda.pred$class
mean(lda.class != crime.test)

# error = 10.67%
```


## QDA

```{r}

set.seed(100)
qda.fit = qda(crime~indus+nox+age+dis+rad+tax,
              data = Boston, subset = train)

qda.class = predict(qda.fit, Boston.test)$class
mean(qda.class != crime.test)

# error = 62.06%
```



## Logistic regression

```{r}
lr.fits = glm(crime~indus+nox+age+dis+rad+tax,
               data = Boston, family = binomial,
               subset = train)

lr.probs = predict(lr.fits, Boston.test, type="response")
lr.pred = rep(0, length(lr.probs))
lr.pred[lr.probs > .5] = 1

mean(lr.pred != crime.test)

# error = 0.09%
```


## KNN

```{r}
# prepare the data
library(class)
train.x = cbind(indus,nox,age,dis,rad,tax)[train, ]
test.x = cbind(indus,nox,age,dis,rad,tax)[test, ]
train.crime = crime[train]

```

```{r}
## KNN for k=1

set.seed(100)
knnpred.1 = knn(train.x, test.x, train.crime, k=1)

# error rate = 62.85%
mean(crime.test != knnpred.1) 
```

```{r}
## KNN for k=5

set.seed(100)
knnpred.5 = knn(train.x, test.x, train.crime, k=5)

# error rate = 12.65%
mean(crime.test != knnpred.5) 
```

```{r}
## KNN for k=10

set.seed(100)
knnpred.10 = knn(train.x, test.x, train.crime, k=10)

# error rate = 11.86%
mean(crime.test != knnpred.10) 
```

Logistic regression seems to have the lowest error rate. KNN also looks potentially interesting with low error rates at some values of k.